# Papers

## Embedding
- [REPRESENTATION DEGENERATION PROBLEM IN TRAINING NATURAL LANGUAGE GENERATION MODELS (ICLR 2019)](https://arxiv.org/pdf/1907.12009.pdf)
  - Code: https://github.com/salesforce/awd-lstm-lm
- [MINILM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers (NeurIPS 2020)](https://arxiv.org/pdf/2002.10957.pdf)
  - Code: https://github.com/microsoft/unilm/tree/master/minilm
  - Code: https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2
  
## Contrastive Learning
- [SimCSE: Simple Contrastive Learning of Sentence Embeddings (EMNLP 2021)](https://arxiv.org/pdf/2104.08821.pdf)
  - Code: https://github.com/princeton-nlp/SimCSE
- [Self-Guided Contrastive Learning for BERT Sentence Representations (ACL 2021)](https://arxiv.org/pdf/2106.07345.pdf)
  - Code: https://github.com/galsang/SG-BERT
- [Supporting Clustering with Contrastive Learning (NACCL 2021)](https://arxiv.org/pdf/2103.12953.pdf)
  - Code: https://github.com/amazon-research/sccl
- [DiffCSE: Difference-based Contrastive Learning for Sentence Embeddings (NACCL 2022)](https://arxiv.org/pdf/2204.10298v1.pdf)
  - Code: https://github.com/voidism/DiffCSE
- [EASE: Entity-Aware Contrastive Learning of Sentence Embedding (NACCL 2022)](https://arxiv.org/abs/2205.04260)
  - Code: https://github.com/studio-ousia/ease
- [Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive Representation Learning (Liang et al., 2022 arxiv)](https://arxiv.org/pdf/2203.02053.pdf)
  - code: https://modalitygap.readthedocs.io/en/latest/

## Visualization
- [Visualizing Data using t-SNE (Journal of Machine Learning Research, 2008)](https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf)
  - No code available

## Clustering
- [Variational Wasserstein Clustering (ECCV 2018)](https://arxiv.org/pdf/1806.09045.pdf)
  - Code: https://github.com/icemiliang/pyvot
- [Sinkhorn barycenters with free support via Frank-Wolfe algorithm (NeurIPS 2019)](https://arxiv.org/pdf/1905.13194.pdf)
  - Code: https://github.com/GiulsLu/Sinkhorn-Barycenters
- [Regularized Wasserstein Means for Aligning Distributional Data (AAAI 2020)](https://arxiv.org/pdf/1812.00338.pdf)
  - Code: https://github.com/icemiliang/pyvot
- [DECWA : Density-Based Clustering using Wasserstein Distance (CIKM 2020)](https://sci-hub.se/https://dl.acm.org/doi/10.1145/3340531.3412125)
  - No code available
- [Wasserstein K-means for clustering probability distributions (NeurIPS 2022)](https://arxiv.org/pdf/2209.06975.pdf)
  - Code: https://github.com/Yubo02/Wasserstein-K-means-for-clustering-probability-distributions
- [New Intent Discovery with Pre-training and Contrastive Learning (ACL 2022)](https://arxiv.org/pdf/2205.12914.pdf)
  - Code: [https://github.com/zhang-yu-wei/MTP-CLNN](https://github.com/fanolabs/NID_ACLARR2022)
- [KNN-Contrastive Learning for Out-of-Domain Intent Classification (ACL 2022)](https://aclanthology.org/2022.acl-long.352.pdf)
  - Code: https://github.com/zyh190507/KnnContrastiveForOOD 

## The Others
- [Convexity of the support of the displacement interpolation: Counterexamples (Santambrogio and Wang., Applied Mathematics Letters 2016)](https://hal.archives-ouvertes.fr/hal-01214200/document)
  - No code available
- [Dialog Intent Induction with Deep Multi-View Clustering (EMNLP 2020)](https://arxiv.org/pdf/1908.11487.pdf)
  - Code: https://github.com/asappresearch/dialog-intent-induction
- [Effectiveness of Pre-training for Few-shot Intent Classification (EMNLP 2021)](https://aclanthology.org/2021.findings-emnlp.96.pdf)
  - Code: https://github.com/fanolabs/IntentBert
- [Automatic Intent-Slot Induction for Dialogue Systems (WWW 2021)](https://arxiv.org/pdf/2103.08886.pdf)
  - No code available
- [Learning to Classify Open Intent via Soft Labeling and Manifold Mixup (IEEE/ACM Transactions on Audio Speech and Language Processing 2021)](https://arxiv.org/pdf/2204.07804.pdf)
  - Code: https://github.com/zifengcheng/SLMM
- [Dialog Intent Induction via Density-based Deep Clustering Ensemble (DSTC10 at AAAI 2022)](https://arxiv.org/pdf/2201.06731.pdf)
  - No code available
- [Gaining Insights into Unrecognized User Utterances in Task-Oriented Dialog Systems (arxiv 2022)](https://arxiv.org/pdf/2204.05158.pdf)
  - No code available
- [A Simple Meta-learning Paradigm for Zero-shot Intent Classification with Mixture Attention Mechanism (SIGIR 2022)](https://arxiv.org/pdf/2206.02179.pdf)
  - No code available



# Others
- [K-means++](https://hleecaster.com/k-means-clustering-concept/)
- [Radial basis function](http://www.scholarpedia.org/article/Radial_basis_function)
- [Harmonic map](https://en.wikipedia.org/wiki/Harmonic_map)
- [Bregman method](https://en.wikipedia.org/wiki/Bregman_method)
- [Hausdorff space](https://en.wikipedia.org/wiki/Hausdorff_space)
- [HAUSDORFF LIMITS](https://math.mcmaster.ca/~speisseg/blog/?p=1458)
- [Lipschitz continuity](https://light-tree.tistory.com/188)
- [Singular Value Decomposition](https://angeloyeo.github.io/2019/08/01/SVD.html)
- [The Geometric Meaning of Covariance](https://towardsdatascience.com/the-geometric-meaning-of-covariance-f8e6df967111)
- [Operator norm calculation for simple matrix](https://math.stackexchange.com/questions/2670350/operator-norm-calculation-for-simple-matrix)
- [CUTOFF FOR EXACT RECOVERY OF GAUSSIAN MIXTURE MODELS](https://arxiv.org/pdf/2001.01194.pdf)
- [Riemannian Manifold](https://enginius.tistory.com/m/685)
- [Is a sample covariance matrix always symmetric and positive definite?](https://stats.stackexchange.com/questions/52976/is-a-sample-covariance-matrix-always-symmetric-and-positive-definite)
- [Matrix Decompositions](https://codingsmu.tistory.com/m/65)
- [Cholesky decomposition](https://carstart.tistory.com/m/155)
- [The hardness of k-means clustering in the plane](https://cseweb.ucsd.edu/~avattani/papers/kmeans_hardness.pdf)
- [Linear Programming](https://convex-optimization-for-all.github.io/contents/chapter05/2021/02/08/05_01_Linear_Programming_(LP)/)
- [Slack variable](https://unsolvedproblem.github.io/laon/2019/01/27/laon_machine_learning_study_week2-3.html)
- [Concave and convex functions of a single variable](https://mjo.osborne.economics.utoronto.ca/index.php/tutorial/index/1/cv1/t)
- [Positive-Definite](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=sw4r&logNo=221157302215)
- [Rank](https://m.blog.naver.com/sw4r/221416614473)
- [SDP relaxation](https://velog.io/@wjleekr927/SDP-relaxation)
- [Quantile](https://en.wikipedia.org/wiki/Quantile)
- [Quantile Function](https://stats.libretexts.org/Bookshelves/Probability_Theory/Applied_Probability_(Pfeiffer)/10%3A_Functions_of_Random_Variables/10.03%3A_The_Quantile_Function)
- [Pushfoward](https://elementary-physics.tistory.com/51)
- [Pushfoward2](https://twitter.com/gabrielpeyre/status/1323142797424209920)
- [Diffeomorphism](https://elementary-physics.tistory.com/48)
- [Density matrix](https://en.wikipedia.org/wiki/Density_matrix)
- [Quantum state](https://en.wikipedia.org/wiki/Quantum_state)
- [Bures metric](https://en.wikipedia.org/wiki/Bures_metric)
- [ON THE BURES-WASSERSTEIN DISTANCE BETWEEN POSITIVE DEFINITE MATRICES](https://arxiv.org/pdf/1712.01504.pdf)
- [Lloyd's algorithm](http://datacrew.tech/vector-quantization/)
- [Parallelogram law](https://en.wikipedia.org/wiki/Parallelogram_law)
- [Optimal Transport](https://hongl.tistory.com/132)
- [Alexandrov space](https://arxiv.org/pdf/2102.02112.pdf)
- [Alexandrov curvature](https://math.berkeley.edu/~lott/zlott.pdf)
- [A generalization of the parallelogram law to higher dimensions](https://amc-journal.eu/index.php/amc/article/download/1704/1305)
- [t-SNE](https://gaussian37.github.io/ml-concept-t_sne/)
- [Silhouette score](https://studying-haeung.tistory.com/10)
- [Hyperopt](https://github.com/hyperopt/hyperopt)
- [t-SNE vs UMAP](https://data-newbie.tistory.com/295)
- [DBSCAN](https://pizzathief.oopy.io/dbscan)
- [Wasserstein GAN](https://www.slideshare.net/ssuser7e10e4/wasserstein-gan-i)
- [Wasserstein distance](https://rosinality.github.io/2017/04/wasserstein-%EA%B1%B0%EB%A6%AC/)
- [Why Wasserstein distance?](https://kowshikchilamkurthy.medium.com/wasserstein-distance-contraction-mapping-and-modern-rl-theory-93ef740ae867)
- [Why Wasserstein is indeed weak](http://proceedings.mlr.press/v70/arjovsky17a/arjovsky17a-supp.pdf)
- [KL-Divergence](https://hyunw.kim/blog/2017/10/27/KL_divergence.html)
- [Wasserstein Barycenter Applied to K-Means Clustering](https://math.nyu.edu/media/math/filer_public/4e/81/4e810c50-3843-45f4-8c21-ea97ef3b84fe/wasserstein_barycenter_applied_to_k-means_clustering.pdf)
- [metric](https://haawron.tistory.com/21)
